import {
    Box,
    Card,
    Image,
    Heading,
    Text,
    Flex,
    Link
} from 'rebass';

export const docker = "https://www.docker.com/"
export const containerTrainingGithub = "https://github.com/jpetazzo/container.training"
export const containerTrainingSlides = "https://container.training/"
export const slide23 = "https://container.training/intro-selfpaced.yml.html#23"
export const slide25 = "https://container.training/intro-selfpaced.yml.html#25"
export const slide26 = "https://container.training/intro-selfpaced.yml.html#26"
export const slide28 = "https://container.training/intro-selfpaced.yml.html#28"
export const dockerAlternatives = "https://containerjournal.com/topics/container-ecosystems/5-container-alternatives-to-docker/"
export const dockerRun = "https://docs.docker.com/engine/reference/run/"
export const dockerNode = "https://hub.docker.com/_/node"
export const dockerCompose = "https://docs.docker.com/compose/"

export const Repo = "https://github.com/arthurdayton116/aws-terraform/tree/main/terraform_vpc"

#### Why using Docker for local development is so huge and yet so hard to convince devs to do
I do a lot of programming in a lot of different languages at different times for different reasons on different machines in different places.  One of the inevitable side effects of this is the dreaded "it works on [insert wherever your not here]".  I experience this effect on steroids when doing pipeline development where I can never count on the current version of the os or toolchain being used to perform any particular task.  The most recent incarnation of this happened when my 12 year old son asked me to teach him how to deploy his own minecraft server and learn to code.  Stop me if you've heard this one before - he has a Windows machine and I have a Mac - putting aside whether teaching a kid to program on a Windows machine is child abuse - I was faced with instant problems with pathing related to Terraform.

<br/>

The problem with developing on your local machine and using the product of your development is beautifully illustrated in some images I borrowed from
<Link href={containerTrainingSlides} target="_blank">this fantastic project</Link> by Jérôme Petazzoni.

<br/>

The corresponding <Link href={containerTrainingGithub} target="_blank">github repo</Link> is the single best resource I have found for leaning and teacing about containers and I highly recommend it.  Take the time to learn how to build the slides and you will realize just what an invaluable resource this really is.

<br/>

We can see in these four images how the problem of distributing code across multiple hardware creates problems and how the shipping indutry is a great analogy.  Ultimately we need a way to encapsulate our cide with it's configuration and dependencies in a reliable way that can be executed anywhere.

<br/>

#### The deployment problem
<Image p={4} verticalAlign='middle' src="/images/4/slide23.png" />
<Link p={1} href={slide23} target="_blank">Slide 23</Link>

#### The parallel with the shipping industry
<Image p={4} verticalAlign='middle' src="/images/4/slide25.png" />
<Link p={1} href={slide25} target="_blank">Slide 25</Link>

#### Intermodal shipping containers
<Image p={4} verticalAlign='middle' src="/images/4/slide26.png" />
<Link p={1} href={slide26} target="_blank">Slide 26</Link>

#### A shipping container system for applications
<Image p={4} verticalAlign='middle' src="/images/4/slide28.png" />
<Link p={1} href={slide28} target="_blank">Slide 28</Link>

<Image p={4} verticalAlign='middle' src="/images/4/dockerproblem.png" />


Using <Link href={docker} target="_blank">Docker</Link>, or <Link href={dockerAlternatives} target="_blank">other container runtime environments</Link>, you can divorce the OS, executables and configuration from the local environment.  This lends itself directly to making it easier to prepare your applications for Kubernetes or any of the various cloud flavors of container instances.

<br/>

Most importantly it gives you a way to define your development environment as code so when you share it with someone else or come back to it 6 months later you don't have to try and figure out what the magic state of your machine was when you created it.

<br/>

Some examples of how I use this in my own life include:

##### This blog:
    I use github as I showed in <Link href="/post/1/" target="_blank">my first post</Link>.  When I want to work on a post locally I don't want to be dependent on what machine I'm on or what the configuration was the last time I used it so I use a simple docker run command to stand up my local environment:

```go
docker run
-v `pwd`:/mnt
--workdir /mnt
-p 4000:3000
-i -t node:15.12.0-buster /bin/bash -c "npm install -g nodemon; npm install; nodemon -d 30 -P 10000 --watch src start"
```

If we decompose this command we can see a lot of super cool stuff going on.  Running top to bottom we have <Link href={dockerRun} target="_blank">docker run</Link> described by docker as:

> Docker runs processes in isolated containers. A container is a process which runs on a host. The host may be local or remote. When an operator executes docker run, the container process that runs is isolated in that it has its own file system, its own networking, and its own isolated process tree separate from the host.

After that comes one of the things I love most about Docker, -v, which mounts my local git repository to the container as part of its file system.  This has two crucially useful side effects.

- Anything I do inside the container that needs to be preserved, such as npm install that would write to package json, is written to my local directory.
- Any changes I make to my source files locally via my IDE are written to the file system inside the container.

Next comes --workdir which sets the working directory and allows me to determine the context for when I enter the container and where any commands I issue will be executed.

Then we have -p which maps a local port to a container port.  In this case I am saying use my local port 4000 to route to the container port 3000.  This is super handy when we have multiple container services running that all use the same code base and configuration.

The last line starts with the -i and -t options which means run this container interactively so I can watch whats going on in my terminal as commands and requests are executed.  The image I use to start my container is defined by <Link href={dockerNode} target="_blank">node:15.12.0-buster</Link> which gives me both an image created by the NodeJS team and pins it to a specific version.  Lastly we have the command I want to run which says globally install nodemon then do npm install and finally start a development server with nodemon and watch for file changes as I develop.

##### Terraform
Similarly for Terraform I can use their officially maintained image to execute my local code by starting an interactive container mounted to a directory

<Image p={4} verticalAlign='middle' src="/images/4/finder.png" />

```
docker run
--entrypoint /bin/sh
-v `pwd`:/mnt
--workdir /mnt/peering/terraform_vpc_peering
-i -t  hashicorp/terraform:0.14.8
```

##### GoApi
In a more complex scenario when I want to run multiple API endpoint locally to test some microservices I can use <Link href={dockerCompose} target="_blank">docker compose</Link>to define multiple conatainer instances and start them as a group using docker-compose up.  Here I create a docker-compose.yml file that mounts the same source code (volumes) to 3 separate containers (api1, api2, api3) using the same base image (golang:1.16.2-buster) from the Go team and map the container port (1323) to different host ports (3140, 3150, 3160).

```go
version: "3.9"

services:
  api1:
    image: golang:1.16.2-buster
    working_dir: /go/src
    command: go run .
    volumes:
      - ./src:/go/src
    ports:
      - "3140:1323"
    environment:
      -  SWAGGER_HOST=localhost:3140
      -  SWAGGER_BASE_PATH=/
      -  TARGETOS=linux
      -  TARGETARCH=amd64
      -  PRIVATE_IP=123.456
      -  PRIVATE_DNS=localhost1
      -  SECURITY_GROUP=public
      -  AVAILABILTY_ZONE=A
  api2:
    image: golang:1.16.2-buster
    working_dir: /go/src
    command: go run .
    volumes:
      - ./src:/go/src
    ports:
      - "3150:1323"
    environment:
      -  SWAGGER_HOST=localhost:3150
      -  SWAGGER_BASE_PATH=/
      -  TARGETOS=linux
      -  TARGETARCH=amd64
      - PRIVATE_IP=789.101
      - PRIVATE_DNS=localhost2
      - SECURITY_GROUP=private
      - AVAILABILTY_ZONE=B
  api3:
    image: golang:1.16.2-buster
    working_dir: /go/src
    command: go run .
    volumes:
      - ./src:/go/src
    ports:
      - "3160:1323"
    environment:
      - SWAGGER_HOST=localhost:3160
      - SWAGGER_BASE_PATH=/
      - TARGETOS=linux
      - TARGETARCH=amd64
      - PRIVATE_IP=678.456
      - PRIVATE_DNS=localhost3
      - SECURITY_GROUP=public
      - AVAILABILTY_ZONE=C
```

<br/>
##### Conclusion

Hopefully what these examples show is how easy it is to use container technology to codify development environments for reliable and repeatable local use with the only requirement being the presence of the Docker runtime.  Not using containers for local development leads to slower and more painful development as the size of your team and the number of other teams you collaborate with increases.

<br/>
